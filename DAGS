from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.providers.mysql.operators.mysql import MySqlOperator
from datetime import datetime
import pandas as pd
import time
import mysql.connector

# Configuración
CSV_FILE_PATH = "/opt/airflow/dags/migration_original.csv"
MYSQL_HOST = "172.23.0.8"
MYSQL_USER = "root"
MYSQL_PASSWORD = "miclave"
MYSQL_DATABASE = "taller4"

# Función para seleccionar y renombrar campos
def select_and_rename_fields(**kwargs):
    df = pd.read_csv(CSV_FILE_PATH)
    selected_columns = ['event-id', 'visible', 'timestamp', 'location-long', 'location-lat']
    df = df[selected_columns]
    df.columns = [col.replace('-', '_') for col in df.columns]
    kwargs['ti'].xcom_push(key='processed_df', value=df.to_dict(orient='records'))

# Función para cargar datos procesados en MySQL con intervalos de 2 segundos
def load_csv_to_mysql(**kwargs):
    records = kwargs['ti'].xcom_pull(key='processed_df', task_ids='process_csv')
    df = pd.DataFrame(records)
    
    conn = mysql.connector.connect(
        host=MYSQL_HOST,
        user=MYSQL_USER,
        password=MYSQL_PASSWORD,
        database=MYSQL_DATABASE
    )
    cursor = conn.cursor()

    cols = ", ".join(df.columns)
    values_placeholder = ", ".join(["%s"] * len(df.columns))
    insert_query = f"INSERT INTO migracion ({cols}) VALUES ({values_placeholder})"
    
    for _, row in df.iterrows():
        cursor.execute(insert_query, tuple(row))
        conn.commit()
        time.sleep(1) 
    
    cursor.close()
    conn.close()

# Definir DAG
default_args = {
    'owner': 'airflow',
    'retries': 1,
    'retry_delay': 300,
}

with DAG(
    dag_id="1_process_csv_dag_realtime",
    default_args=default_args,
    description="DAG para procesar y cargar datos en MySQL cada 2 segundos",
    schedule_interval="@daily",
    start_date=datetime(2023, 1, 1),
    catchup=False
) as dag:
    
    process_csv = PythonOperator(
        task_id="process_csv",
        python_callable=select_and_rename_fields,
        provide_context=True
    )
    
    create_table = MySqlOperator(
        task_id="create_table",
        mysql_conn_id="mysql_default",
        sql="""
        CREATE TABLE IF NOT EXISTS taller4.migracion (
            event_id INT,
            visible BOOLEAN,
            timestamp DATETIME,
            location_long FLOAT,
            location_lat FLOAT
        );
        """
    )
    
    load_data = PythonOperator(
        task_id="load_data",
        python_callable=load_csv_to_mysql,
        provide_context=True
    )
    
    process_csv >> create_table >> load_data
